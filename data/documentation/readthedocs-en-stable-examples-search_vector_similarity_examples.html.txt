Vector Similarity# Index Creation# KNN Queries# Vectors (also called “Embeddings”), represent an AI model’s impression (or understanding) of a piece of unstructured data like text, images, audio, videos, etc. Vector Similarity Search (VSS) is the process of finding vectors in the vector database that are similar to a given query vector. Popular VSS uses include recommendation systems, image and video search, document retrieval, and question answering. Before doing vector search, first define the schema and create an index. We’ll start by working with vectors that have 1536 dimensions. Next, we add vectors (dummy data) to Redis using hset. The search index listens to keyspace notifications and will include any written HASH objects prefixed by DOC_PREFIX. You can use VSS queries with the .ft(...).search(...) query command. To use a VSS query, you must specify the option .dialect(2). There are two supported types of vector queries in Redis: KNN and Range. Hybrid queries can work in both settings and combine elements of traditional search and VSS. KNN queries are for finding the topK most similar vectors given a query vector. Range queries provide a way to filter results by the distance between a vector field in Redis and a query vector based on some pre-defined threshold (radius). See additional Range Query examples in this Jupyter notebook. Hybrid queries contain both traditional filters (numeric, tags, text) and VSS in one single Redis command. See additional Hybrid Query examples in this Jupyter notebook. The above examples use dummy data as vectors. However, in reality, most use cases leverage production-grade AI models for creating embeddings. Below we will take some sample text data, pass it to the OpenAI and Cohere API’s respectively, and then write them to Redis. Before working with OpenAI Embeddings, we clean up our existing search index and create a new one. Now that we’ve created embeddings with OpenAI, we can also perform a search to find relevant documents to some input text. Before working with Cohere Embeddings, we clean up our existing search index and create a new one. Now that we’ve created embeddings with Cohere, we can also perform a search to find relevant documents to some input text. Find more example apps, tutorials, and projects using Redis Vector Similarity Search in this GitHub organization.  importredisfromredis.commands.search.fieldimportTagField,VectorFieldfromredis.commands.search.indexDefinitionimportIndexDefinition,IndexTypefromredis.commands.search.queryimportQueryr=redis.Redis(host="localhost",port=6379)INDEX_NAME="index"# Vector Index NameDOC_PREFIX="doc:"# RediSearch Key Prefix for the Indexdefcreate_index(vector_dimensions:int):try:# check to see if index existsr.ft(INDEX_NAME).info()print("Index already exists!")except:# schemaschema=(TagField("tag"),# Tag Field NameVectorField("vector",# Vector Field Name"FLAT",{# Vector Index Type: FLAT or HNSW"TYPE":"FLOAT32",# FLOAT32 or FLOAT64"DIM":vector_dimensions,# Number of Vector Dimensions"DISTANCE_METRIC":"COSINE",# Vector Search Distance Metric}),)# index Definitiondefinition=IndexDefinition(prefix=[DOC_PREFIX],index_type=IndexType.HASH)# create Indexr.ft(INDEX_NAME).create_index(fields=schema,definition=definition)  # define vector dimensionsVECTOR_DIMENSIONS=1536# create the indexcreate_index(vector_dimensions=VECTOR_DIMENSIONS)  %pip  importnumpyasnp  # instantiate a redis pipelinepipe=r.pipeline()# define some dummy dataobjects=[{"name":"a","tag":"foo"},{"name":"b","tag":"foo"},{"name":"c","tag":"bar"},]# write dataforobjinobjects:# define keykey=f"doc:{obj['name']}"# create a random "dummy" vectorobj["vector"]=np.random.rand(VECTOR_DIMENSIONS).astype(np.float32).tobytes()# HSETpipe.hset(key,mapping=obj)res=pipe.execute()  query=(Query("*=>[KNN 2 @vector $vec as score]").sort_by("score").return_fields("id","score").return_field("vector",decode_field=False)# return the vector field as bytes.paging(0,2).dialect(2))query_params={"vec":np.random.rand(VECTOR_DIMENSIONS).astype(np.float32).tobytes()}r.ft(INDEX_NAME).search(query,query_params).docs    query=(Query("@vector:[VECTOR_RANGE $radius $vec]=>{$YIELD_DISTANCE_AS: score}").sort_by("score").return_fields("id","score").paging(0,3).dialect(2))# Find all vectors within 0.8 of the query vectorquery_params={"radius":0.8,"vec":np.random.rand(VECTOR_DIMENSIONS).astype(np.float32).tobytes()}r.ft(INDEX_NAME).search(query,query_params).docs    query=(Query("(@tag:{ foo })=>[KNN 2 @vector $vec as score]").sort_by("score").return_fields("id","tag","score").paging(0,2).dialect(2))query_params={"vec":np.random.rand(VECTOR_DIMENSIONS).astype(np.float32).tobytes()}r.ft(INDEX_NAME).search(query,query_params).docs    texts=["Today is a really great day!","The dog next door barks really loudly.","My cat escaped and got out before I could close the door.","It's supposed to rain and thunder tomorrow."]  # delete indexr.ft(INDEX_NAME).dropindex(delete_documents=True)# make a new onecreate_index(vector_dimensions=VECTOR_DIMENSIONS)  %pip  importopenai# set your OpenAI API key - get one at https://platform.openai.comopenai.api_key="YOUR OPENAI API KEY"  # Create Embeddings with OpenAI text-embedding-ada-002# https://openai.com/blog/new-and-improved-embedding-modelresponse=openai.Embedding.create(input=texts,engine="text-embedding-ada-002")embeddings=np.array([r["embedding"]forrinresponse["data"]],dtype=np.float32)# Write to Redispipe=r.pipeline()fori,embeddinginenumerate(embeddings):pipe.hset(f"doc:{i}",mapping={"vector":embedding.tobytes(),"content":texts[i],"tag":"openai"})res=pipe.execute()  embeddings    text="animals"# create query embeddingresponse=openai.Embedding.create(input=[text],engine="text-embedding-ada-002")query_embedding=np.array([r["embedding"]forrinresponse["data"]],dtype=np.float32)[0]query_embedding    # query for similar documents that have the openai tagquery=(Query("(@tag:{ openai })=>[KNN 2 @vector $vec as score]").sort_by("score").return_fields("content","tag","score").paging(0,2).dialect(2))query_params={"vec":query_embedding.tobytes()}r.ft(INDEX_NAME).search(query,query_params).docs# the two pieces of content related to animals are returned    # delete indexr.ft(INDEX_NAME).dropindex(delete_documents=True)# make a new one for cohere embeddings (1024 dimensions)VECTOR_DIMENSIONS=1024create_index(vector_dimensions=VECTOR_DIMENSIONS)  %pip  importcohereco=cohere.Client("YOUR COHERE API KEY")  # Create Embeddings with Cohere# https://docs.cohere.ai/docs/embeddingsresponse=co.embed(texts=texts,model="small")embeddings=np.array(response.embeddings,dtype=np.float32)# Write to Redisfori,embeddinginenumerate(embeddings):r.hset(f"doc:{i}",mapping={"vector":embedding.tobytes(),"content":texts[i],"tag":"cohere"})  embeddings    text="animals"# create query embeddingresponse=co.embed(texts=[text],model="small")query_embedding=np.array(response.embeddings[0],dtype=np.float32)query_embedding    # query for similar documents that have the cohere tagquery=(Query("(@tag:{ cohere })=>[KNN 2 @vector $vec as score]").sort_by("score").return_fields("content","tag","score").paging(0,2).dialect(2))query_params={"vec":query_embedding.tobytes()}r.ft(INDEX_NAME).search(query,query_params).docs# the two pieces of content related to animals are returned    Index Creation# Before doing vector search, first define the schema and create an index. We’ll start by working with vectors that have 1536 dimensions.  importredisfromredis.commands.search.fieldimportTagField,VectorFieldfromredis.commands.search.indexDefinitionimportIndexDefinition,IndexTypefromredis.commands.search.queryimportQueryr=redis.Redis(host="localhost",port=6379)INDEX_NAME="index"# Vector Index NameDOC_PREFIX="doc:"# RediSearch Key Prefix for the Indexdefcreate_index(vector_dimensions:int):try:# check to see if index existsr.ft(INDEX_NAME).info()print("Index already exists!")except:# schemaschema=(TagField("tag"),# Tag Field NameVectorField("vector",# Vector Field Name"FLAT",{# Vector Index Type: FLAT or HNSW"TYPE":"FLOAT32",# FLOAT32 or FLOAT64"DIM":vector_dimensions,# Number of Vector Dimensions"DISTANCE_METRIC":"COSINE",# Vector Search Distance Metric}),)# index Definitiondefinition=IndexDefinition(prefix=[DOC_PREFIX],index_type=IndexType.HASH)# create Indexr.ft(INDEX_NAME).create_index(fields=schema,definition=definition)  # define vector dimensionsVECTOR_DIMENSIONS=1536# create the indexcreate_index(vector_dimensions=VECTOR_DIMENSIONS)  Adding Vectors to Redis# Next, we add vectors (dummy data) to Redis using hset. The search index listens to keyspace notifications and will include any written HASH objects prefixed by DOC_PREFIX.  %pip  importnumpyasnp  # instantiate a redis pipelinepipe=r.pipeline()# define some dummy dataobjects=[{"name":"a","tag":"foo"},{"name":"b","tag":"foo"},{"name":"c","tag":"bar"},]# write dataforobjinobjects:# define keykey=f"doc:{obj['name']}"# create a random "dummy" vectorobj["vector"]=np.random.rand(VECTOR_DIMENSIONS).astype(np.float32).tobytes()# HSETpipe.hset(key,mapping=obj)res=pipe.execute()  Searching# KNN Queries# You can use VSS queries with the .ft(...).search(...) query command. To use a VSS query, you must specify the option .dialect(2). There are two supported types of vector queries in Redis: KNN and Range. Hybrid queries can work in both settings and combine elements of traditional search and VSS. KNN queries are for finding the topK most similar vectors given a query vector. Range queries provide a way to filter results by the distance between a vector field in Redis and a query vector based on some pre-defined threshold (radius). See additional Range Query examples in this Jupyter notebook. Hybrid queries contain both traditional filters (numeric, tags, text) and VSS in one single Redis command. See additional Hybrid Query examples in this Jupyter notebook.  query=(Query("*=>[KNN 2 @vector $vec as score]").sort_by("score").return_fields("id","score").return_field("vector",decode_field=False)# return the vector field as bytes.paging(0,2).dialect(2))query_params={"vec":np.random.rand(VECTOR_DIMENSIONS).astype(np.float32).tobytes()}r.ft(INDEX_NAME).search(query,query_params).docs    query=(Query("@vector:[VECTOR_RANGE $radius $vec]=>{$YIELD_DISTANCE_AS: score}").sort_by("score").return_fields("id","score").paging(0,3).dialect(2))# Find all vectors within 0.8 of the query vectorquery_params={"radius":0.8,"vec":np.random.rand(VECTOR_DIMENSIONS).astype(np.float32).tobytes()}r.ft(INDEX_NAME).search(query,query_params).docs    query=(Query("(@tag:{ foo })=>[KNN 2 @vector $vec as score]").sort_by("score").return_fields("id","tag","score").paging(0,2).dialect(2))query_params={"vec":np.random.rand(VECTOR_DIMENSIONS).astype(np.float32).tobytes()}r.ft(INDEX_NAME).search(query,query_params).docs    KNN Queries# KNN queries are for finding the topK most similar vectors given a query vector.  query=(Query("*=>[KNN 2 @vector $vec as score]").sort_by("score").return_fields("id","score").return_field("vector",decode_field=False)# return the vector field as bytes.paging(0,2).dialect(2))query_params={"vec":np.random.rand(VECTOR_DIMENSIONS).astype(np.float32).tobytes()}r.ft(INDEX_NAME).search(query,query_params).docs    Range Queries# Range queries provide a way to filter results by the distance between a vector field in Redis and a query vector based on some pre-defined threshold (radius). See additional Range Query examples in this Jupyter notebook.  query=(Query("@vector:[VECTOR_RANGE $radius $vec]=>{$YIELD_DISTANCE_AS: score}").sort_by("score").return_fields("id","score").paging(0,3).dialect(2))# Find all vectors within 0.8 of the query vectorquery_params={"radius":0.8,"vec":np.random.rand(VECTOR_DIMENSIONS).astype(np.float32).tobytes()}r.ft(INDEX_NAME).search(query,query_params).docs    Hybrid Queries# Hybrid queries contain both traditional filters (numeric, tags, text) and VSS in one single Redis command. See additional Hybrid Query examples in this Jupyter notebook.  query=(Query("(@tag:{ foo })=>[KNN 2 @vector $vec as score]").sort_by("score").return_fields("id","tag","score").paging(0,2).dialect(2))query_params={"vec":np.random.rand(VECTOR_DIMENSIONS).astype(np.float32).tobytes()}r.ft(INDEX_NAME).search(query,query_params).docs    Vector Creation and Storage Examples# OpenAI Embeddings# The above examples use dummy data as vectors. However, in reality, most use cases leverage production-grade AI models for creating embeddings. Below we will take some sample text data, pass it to the OpenAI and Cohere API’s respectively, and then write them to Redis. Before working with OpenAI Embeddings, we clean up our existing search index and create a new one. Now that we’ve created embeddings with OpenAI, we can also perform a search to find relevant documents to some input text. Before working with Cohere Embeddings, we clean up our existing search index and create a new one. Now that we’ve created embeddings with Cohere, we can also perform a search to find relevant documents to some input text. Find more example apps, tutorials, and projects using Redis Vector Similarity Search in this GitHub organization.  texts=["Today is a really great day!","The dog next door barks really loudly.","My cat escaped and got out before I could close the door.","It's supposed to rain and thunder tomorrow."]  # delete indexr.ft(INDEX_NAME).dropindex(delete_documents=True)# make a new onecreate_index(vector_dimensions=VECTOR_DIMENSIONS)  %pip  importopenai# set your OpenAI API key - get one at https://platform.openai.comopenai.api_key="YOUR OPENAI API KEY"  # Create Embeddings with OpenAI text-embedding-ada-002# https://openai.com/blog/new-and-improved-embedding-modelresponse=openai.Embedding.create(input=texts,engine="text-embedding-ada-002")embeddings=np.array([r["embedding"]forrinresponse["data"]],dtype=np.float32)# Write to Redispipe=r.pipeline()fori,embeddinginenumerate(embeddings):pipe.hset(f"doc:{i}",mapping={"vector":embedding.tobytes(),"content":texts[i],"tag":"openai"})res=pipe.execute()  embeddings    text="animals"# create query embeddingresponse=openai.Embedding.create(input=[text],engine="text-embedding-ada-002")query_embedding=np.array([r["embedding"]forrinresponse["data"]],dtype=np.float32)[0]query_embedding    # query for similar documents that have the openai tagquery=(Query("(@tag:{ openai })=>[KNN 2 @vector $vec as score]").sort_by("score").return_fields("content","tag","score").paging(0,2).dialect(2))query_params={"vec":query_embedding.tobytes()}r.ft(INDEX_NAME).search(query,query_params).docs# the two pieces of content related to animals are returned    # delete indexr.ft(INDEX_NAME).dropindex(delete_documents=True)# make a new one for cohere embeddings (1024 dimensions)VECTOR_DIMENSIONS=1024create_index(vector_dimensions=VECTOR_DIMENSIONS)  %pip  importcohereco=cohere.Client("YOUR COHERE API KEY")  # Create Embeddings with Cohere# https://docs.cohere.ai/docs/embeddingsresponse=co.embed(texts=texts,model="small")embeddings=np.array(response.embeddings,dtype=np.float32)# Write to Redisfori,embeddinginenumerate(embeddings):r.hset(f"doc:{i}",mapping={"vector":embedding.tobytes(),"content":texts[i],"tag":"cohere"})  embeddings    text="animals"# create query embeddingresponse=co.embed(texts=[text],model="small")query_embedding=np.array(response.embeddings[0],dtype=np.float32)query_embedding    # query for similar documents that have the cohere tagquery=(Query("(@tag:{ cohere })=>[KNN 2 @vector $vec as score]").sort_by("score").return_fields("content","tag","score").paging(0,2).dialect(2))query_params={"vec":query_embedding.tobytes()}r.ft(INDEX_NAME).search(query,query_params).docs# the two pieces of content related to animals are returned    OpenAI Embeddings# Before working with OpenAI Embeddings, we clean up our existing search index and create a new one.  # delete indexr.ft(INDEX_NAME).dropindex(delete_documents=True)# make a new onecreate_index(vector_dimensions=VECTOR_DIMENSIONS)  %pip  importopenai# set your OpenAI API key - get one at https://platform.openai.comopenai.api_key="YOUR OPENAI API KEY"  # Create Embeddings with OpenAI text-embedding-ada-002# https://openai.com/blog/new-and-improved-embedding-modelresponse=openai.Embedding.create(input=texts,engine="text-embedding-ada-002")embeddings=np.array([r["embedding"]forrinresponse["data"]],dtype=np.float32)# Write to Redispipe=r.pipeline()fori,embeddinginenumerate(embeddings):pipe.hset(f"doc:{i}",mapping={"vector":embedding.tobytes(),"content":texts[i],"tag":"openai"})res=pipe.execute()  embeddings    Search with OpenAI Embeddings# Now that we’ve created embeddings with OpenAI, we can also perform a search to find relevant documents to some input text.  text="animals"# create query embeddingresponse=openai.Embedding.create(input=[text],engine="text-embedding-ada-002")query_embedding=np.array([r["embedding"]forrinresponse["data"]],dtype=np.float32)[0]query_embedding    # query for similar documents that have the openai tagquery=(Query("(@tag:{ openai })=>[KNN 2 @vector $vec as score]").sort_by("score").return_fields("content","tag","score").paging(0,2).dialect(2))query_params={"vec":query_embedding.tobytes()}r.ft(INDEX_NAME).search(query,query_params).docs# the two pieces of content related to animals are returned    Cohere Embeddings# Before working with Cohere Embeddings, we clean up our existing search index and create a new one.  # delete indexr.ft(INDEX_NAME).dropindex(delete_documents=True)# make a new one for cohere embeddings (1024 dimensions)VECTOR_DIMENSIONS=1024create_index(vector_dimensions=VECTOR_DIMENSIONS)  %pip  importcohereco=cohere.Client("YOUR COHERE API KEY")  # Create Embeddings with Cohere# https://docs.cohere.ai/docs/embeddingsresponse=co.embed(texts=texts,model="small")embeddings=np.array(response.embeddings,dtype=np.float32)# Write to Redisfori,embeddinginenumerate(embeddings):r.hset(f"doc:{i}",mapping={"vector":embedding.tobytes(),"content":texts[i],"tag":"cohere"})  embeddings    Search with Cohere Embeddings# Now that we’ve created embeddings with Cohere, we can also perform a search to find relevant documents to some input text. Find more example apps, tutorials, and projects using Redis Vector Similarity Search in this GitHub organization.  text="animals"# create query embeddingresponse=co.embed(texts=[text],model="small")query_embedding=np.array(response.embeddings[0],dtype=np.float32)query_embedding    # query for similar documents that have the cohere tagquery=(Query("(@tag:{ cohere })=>[KNN 2 @vector $vec as score]").sort_by("score").return_fields("content","tag","score").paging(0,2).dialect(2))query_params={"vec":query_embedding.tobytes()}r.ft(INDEX_NAME).search(query,query_params).docs# the two pieces of content related to animals are returned    